{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San_Diego Crossing: Guatemala\n",
    "- Four SSP Scenarios\n",
    "- Saving output DF and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Imputting libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Saving Model Summaries\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Formatting printing and floats\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Parsing into a dataframe\n",
    "wide_df = pd.read_csv('INPUTS_OUTPUTS_NEW_VARIABLES_ML/INPUT_DATA_SCRIPT_ML/Guatemala/GUA_USA_FINAL_VARS.csv')\n",
    "\n",
    "# Dropping columns\n",
    "cols_out = ['CSV', 'Country', 'New_Data_Type']\n",
    "wide_df = wide_df.drop(cols_out, axis=1).copy()\n",
    "\n",
    "# Cleaning/parsing\n",
    "wide_df.iloc[:, 4:] = wide_df.iloc[:, 4:].replace(0, np.nan)  # Replacing all 0 values with NaN values\n",
    "wide_df.iloc[:, 4:] = wide_df.iloc[:, 4:].astype(float)       # Data type to float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse data into numeric\n",
    "\n",
    "def prepare_data(df, year_columns):\n",
    "    df[year_columns] = df[year_columns].apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "# # Function to impute data with OLS\n",
    "\n",
    "def impute_with_ols(df, train_start_year, train_end_year):\n",
    "    # Defining columns\n",
    "    year_columns = [str(year) for year in range(train_start_year, train_end_year + 1)]\n",
    "    # Imputting data\n",
    "    for index, row in df.iterrows():\n",
    "        # Fitting the model only on available data\n",
    "        available_data = row[year_columns].dropna()\n",
    "        if len(available_data) < 2:\n",
    "            continue  # Need at least two data points to fit a line\n",
    "        \n",
    "        # Determining imputation method for each variable\n",
    "        impute_method = {}\n",
    "        for col in available_data.index:\n",
    "            if col in ['GDP (current US$)', 'GDP per capita (current US$)', 'Unemployment, total (% of total labor force) (modeled ILO estimate)']:\n",
    "                impute_method[col] = 'mean'\n",
    "            else:\n",
    "                impute_method[col] = 'median'\n",
    "\n",
    "        # Setting variables for OLS\n",
    "        X_train = np.array(list(map(int, available_data.index))).reshape(-1, 1)\n",
    "        y_train = available_data.values\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predicting missing values\n",
    "        missing_years = row[year_columns][row[year_columns].isna()].index\n",
    "        if missing_years.empty:\n",
    "            continue\n",
    "        X_missing = np.array(list(map(int, missing_years))).reshape(-1, 1)\n",
    "        predicted_values = model.predict(X_missing)\n",
    "        \n",
    "        # Filling missing values in the DataFrame using the appropriate imputation method\n",
    "        for col in missing_years:\n",
    "            if col in impute_method:\n",
    "                if impute_method[col] == 'mean':\n",
    "                    df.loc[index, col] = row[year_columns].mean()\n",
    "                elif impute_method[col] == 'median':\n",
    "                    df.loc[index, col] = row[year_columns].median()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Converting year columns to numeric: 1960 - 2100\n",
    "\n",
    "year_columns = [str(year) for year in range(1960, 2100)]\n",
    "wide_df = prepare_data(wide_df, year_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS : 2015 TO 2022\n",
    "\n",
    "# Perform imputation with OLS for specified years\n",
    "wide_df_processed_data_ols = impute_with_ols(wide_df, 2015, 2022)\n",
    "wide_df_processed_data_ols = wide_df_processed_data_ols\n",
    "\n",
    "# Dropping columns\n",
    "years_to_drop = [str(year) for year in range(1960, 2015)]\n",
    "wide_df_processed_data_ols = wide_df_processed_data_ols.drop(columns=years_to_drop)\n",
    "# wide_df_processed_data_ols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse data into numeric\n",
    "\n",
    "def convert_to_numeric(df):\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            # Force convert to float and handle exceptions\n",
    "            df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "        except ValueError as e:\n",
    "            # Log columns that could not be converted, with error message\n",
    "            print(f\"Column {col} cannot be converted to numeric: {e}\")\n",
    "        except Exception as e:\n",
    "            # Log unexpected exceptions\n",
    "            print(f\"Unexpected error with column {col}: {e}\")\n",
    "    return df\n",
    "\n",
    "# Function for Linear Interpolation\n",
    "\n",
    "def linear_interpolation2(df, start_year, end_year):\n",
    "    # Create a list of year columns\n",
    "    year_columns = [str(year) for year in range(start_year, end_year + 1)]\n",
    "    # Filter out columns that are not in the year range\n",
    "    year_columns = [col for col in year_columns if col in df.columns]\n",
    "\n",
    "    # Convert all potential year columns to numeric\n",
    "    df[year_columns] = convert_to_numeric(df[year_columns])\n",
    "\n",
    "    # Apply linear interpolation to only the year columns\n",
    "    df[year_columns] = df[year_columns].interpolate(method='linear', axis=1, limit_direction='both')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Calling function with specified years\n",
    "\n",
    "wide_df_processed_data_ols = linear_interpolation2(wide_df_processed_data_ols, 1960, 2022)\n",
    "# wide_df_processed_data_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide_df_processed_data_ols['Type__of_Variable'][7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting the dataframe\n",
    "\n",
    "long_df = pd.melt(wide_df_processed_data_ols, id_vars=['Country_Code', 'Variable', \n",
    "                                                       'Unit_of_Measure', 'Type_of_Variable'],\n",
    "                                                         var_name='Year', value_name='Value')\n",
    "\n",
    "# Printing melted dataframe \n",
    "long_df['Year'] = long_df['Year'].astype(int) \n",
    "long_df_22to100 = long_df[long_df['Year'] >= 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import statsmodels.api as sm\n",
    "# from sklearn.datasets import load_iris \n",
    "from math import log\n",
    "import statsmodels.api as sm\n",
    "# from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Filter data for temperature projections and historical data\n",
    "\n",
    "# Historical Data from 1960 to 2022\n",
    "historical_data = long_df[long_df['Year'] <= 2022]\n",
    "# Predicted Data from 2022 to 2100\n",
    "predicted_data = long_df[long_df['Year'] >= 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "\n",
    "# Scenario 1: GUA_SSP119_avg_temp\n",
    "# features_1960_2022_ssp119\n",
    "\n",
    "# Creating a dataframe 'features_1960_2022_ssp119' \n",
    "# Years 1960 to 2022\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'features_ssp119' = X\n",
    "\n",
    "# Filtering data for 'GUA_SSP119_avg_temp'\n",
    "GUA_features_1960_2022_ssp119 = historical_data[historical_data['Variable'] == 'GUA_SSP119_avg_temp'] \n",
    "GUA_features_1960_2022_ssp119 = GUA_features_1960_2022_ssp119[['Year', 'Value']]                            \n",
    "GUA_features_1960_2022_ssp119 = GUA_features_1960_2022_ssp119.rename(columns={'Value': 'Temperature'})      \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Scenario 2: GUA_SSP245_avg_temp\n",
    "# features_1960_2022_ssp245\n",
    "\n",
    "# Creating a dataframe 'features_1960_2022_ssp245' \n",
    "# Years 1960 to 2022\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'features_ssp119' = X\n",
    "\n",
    "# Filtering data for 'GUA_SSP245_avg_temp'\n",
    "GUA_features_1960_2022_ssp245 = historical_data[historical_data['Variable'] == 'GUA_SSP245_avg_temp'] \n",
    "GUA_features_1960_2022_ssp245 = GUA_features_1960_2022_ssp245[['Year', 'Value']]                            \n",
    "GUA_features_1960_2022_ssp245 = GUA_features_1960_2022_ssp245.rename(columns={'Value': 'Temperature'})      \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Scenario 3: GUA_SSP370_avg_temp\n",
    "# features_1960_2022_ssp370\n",
    "\n",
    "# Creating a dataframe 'features_1960_2022_ssp370' \n",
    "# Years 1960 to 2022\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'features_ssp119' = X\n",
    "\n",
    "# Filtering data for 'GUA_SSP245_avg_temp'\n",
    "GUA_features_1960_2022_ssp370 = historical_data[historical_data['Variable'] == 'GUA_SSP370_avg_temp'] \n",
    "GUA_features_1960_2022_ssp370 = GUA_features_1960_2022_ssp370[['Year', 'Value']]                            \n",
    "GUA_features_1960_2022_ssp370 = GUA_features_1960_2022_ssp370.rename(columns={'Value': 'Temperature'})      \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Scenario 4: GUA_SSP585_avg_temp\n",
    "# features_1960_2022_ssp585\n",
    "\n",
    "# Creating a dataframe 'features_1960_2022_ssp585' \n",
    "# Years 1960 to 2022\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'features_ssp119' = X\n",
    "\n",
    "# Filtering data for 'GUA_SSP585_avg_temp'\n",
    "GUA_features_1960_2022_ssp585 = historical_data[historical_data['Variable'] == 'GUA_SSP585_avg_temp'] \n",
    "GUA_features_1960_2022_ssp585 = GUA_features_1960_2022_ssp585[['Year', 'Value']]                            \n",
    "GUA_features_1960_2022_ssp585 = GUA_features_1960_2022_ssp585.rename(columns={'Value': 'Temperature'})      \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Additional Variables to all models\n",
    "# additional_variables: not considering SSP and TRAC data: X\n",
    "additional_variables = [\n",
    "    'Population, total',\n",
    "    'Rural population (% of total population)',\n",
    "    'Population ages 15-64 (% of total population)',\n",
    "    'Unemployment, total (% of total labor force) (modeled ILO estimate)',\n",
    "    'Victims of intentional homicide',\n",
    "    'Prevalence of severe food insecurity in the population (%)',\n",
    "    'Prevalence of undernourishment (% of population)',\n",
    "    'Corruption',\n",
    "    'Government Effectiveness: Estimate',\n",
    "    'GDP (current US$)',\n",
    "    'GDP per capita (current US$)'\n",
    "]\n",
    "    \n",
    "##################################################################\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Scenario 1: _SSP119_avg_temp\n",
    "# features_1960_2022_ssp119\n",
    "# Getting all values from additional_variables into features\n",
    "for var in additional_variables:\n",
    "    var_data = historical_data[historical_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_features_1960_2022_ssp119 = pd.merge(GUA_features_1960_2022_ssp119, var_data, on='Year', how='outer') \n",
    "    \n",
    "# features_1960_2022_ssp119.tail() \n",
    "##################################################################\n",
    "\n",
    "# Scenario 2: _SSP245_avg_temp\n",
    "# features_1960_2022_ssp245\n",
    "# Getting all values from additional_variables into features\n",
    "for var in additional_variables:\n",
    "    var_data = historical_data[historical_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_features_1960_2022_ssp245 = pd.merge(GUA_features_1960_2022_ssp245, var_data, on='Year', how='outer') #CHANGE!!!!!!!!!!!\n",
    "    \n",
    "# features_1960_2022_ssp245.tail() \n",
    "##################################################################\n",
    "\n",
    "# Scenario 3: _SSP370_avg_temp\n",
    "# features_1960_2022_ssp370\n",
    "# Getting all values from additional_variables into features\n",
    "for var in additional_variables:\n",
    "    var_data = historical_data[historical_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_features_1960_2022_ssp370 = pd.merge(GUA_features_1960_2022_ssp370, var_data, on='Year', how='outer') #CHANGE!!!!!!!!!!!\n",
    "    \n",
    "# features_1960_2022_ssp370.tail() \n",
    "##################################################################\n",
    "\n",
    "# Scenario 4: _SSP585_avg_temp\n",
    "# features_1960_2022_ssp585\n",
    "# Getting all values from additional_variables into features\n",
    "for var in additional_variables:\n",
    "    var_data = historical_data[historical_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_features_1960_2022_ssp585 = pd.merge(GUA_features_1960_2022_ssp585, var_data, on='Year', how='outer') #CHANGE!!!!!!!!!!!\n",
    "\n",
    "# features_1960_2022_ssp585.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUA_features_1960_2022_ssp119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historic data on temperature\n",
    "X1_119_GUA = GUA_features_1960_2022_ssp119[['Temperature']]         \n",
    "# Predictions on training data based on temperature\n",
    "Y1_119_GUA = GUA_features_1960_2022_ssp119.drop(columns='Temperature')      \n",
    "# Training model with Ridge Regression for 'GUA_SSP119_avg_temp' based on 'Temperature'\n",
    "model119_GUA = MultiOutputRegressor(Ridge(random_state=123)).fit(X1_119_GUA, Y1_119_GUA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y1_119_GUA.shape    # Y1_119_GUA.shape # (32768, 14)\n",
    "# X1_119_GUA.shape # Y1_119_GUA.shape # (32768, 1)\n",
    "Y1_119_GUA.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model119_GUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Training Data: training all features based on temperature\n",
    "\n",
    "######### Crossing 1: GUA_San_Diego #########\n",
    "# X1 and Y1 are based on features_ssp119 which was filtered with 'GUA_SSP119_avg_temp'\n",
    "\n",
    "# Historic data on temperature\n",
    "X1_119_GUA = GUA_features_1960_2022_ssp119[['Temperature']]         \n",
    "# Predictions on training data based on temperature\n",
    "Y1_119_GUA = GUA_features_1960_2022_ssp119.drop(columns='Temperature')      \n",
    "# Training model with Ridge Regression for 'GUA_SSP119_avg_temp' based on 'Temperature'\n",
    "model119_GUA = MultiOutputRegressor(Ridge(random_state=123)).fit(X1_119_GUA, Y1_119_GUA)\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "# Training Data: training all features based on temperature\n",
    "\n",
    "######### Crossing 1: GUA_San_Diego #########\n",
    "# X1 and Y1 are based on features_ssp245 which was filtered with 'GUA_SSP245_avg_temp'\n",
    "\n",
    "# Historic data on temperature\n",
    "X2_245_GUA = GUA_features_1960_2022_ssp245[['Temperature']]         \n",
    "# Predictions on training data based on temperature\n",
    "Y2_245_GUA = GUA_features_1960_2022_ssp245.drop(columns='Temperature')      \n",
    "# Training model with Ridge Regression for 'GUA_SSP119_avg_temp' based on 'Temperature'\n",
    "model245_GUA = MultiOutputRegressor(Ridge(random_state=123)).fit(X2_245_GUA, Y2_245_GUA)\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "# Training Data: training all features based on temperature\n",
    "\n",
    "######### Crossing 1: GUA_San_Diego #########\n",
    "# X1 and Y1 are based on features_ssp370 which was filtered with 'GUA_SSP370_avg_temp'\n",
    "\n",
    "# Historic data on temperature\n",
    "X3_370_GUA = GUA_features_1960_2022_ssp370[['Temperature']]         \n",
    "# Predictions on training data based on temperature\n",
    "Y3_370_GUA = GUA_features_1960_2022_ssp370.drop(columns='Temperature')      \n",
    "# Training model with Ridge Regression for 'GUA_SSP119_avg_temp' based on 'Temperature'\n",
    "model370_GUA = MultiOutputRegressor(Ridge(random_state=123)).fit(X3_370_GUA, Y3_370_GUA)\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "# Training Data: training all features based on temperature\n",
    "\n",
    "######### Crossing 1: GUA_San_Diego #########\n",
    "# X1 and Y1 are based on features_ssp585 which was filtered with 'GUA_SSP585_avg_temp'\n",
    "\n",
    "# Historic data on temperature\n",
    "X4_585_GUA = GUA_features_1960_2022_ssp585[['Temperature']]         \n",
    "# Predictions on training data based on temperature\n",
    "Y4_585_GUA = GUA_features_1960_2022_ssp585.drop(columns='Temperature')      \n",
    "# Training model with Ridge Regression for 'GUA_SSP119_avg_temp' based on 'Temperature'\n",
    "model585_GUA = MultiOutputRegressor(Ridge(random_state=123)).fit(X4_585_GUA, Y4_585_GUA)\n",
    "\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Dataframe: 2023 to 2100 (predicted_data)\n",
    "##################################################################\n",
    "\n",
    "# Additional Variables to all models\n",
    "# additional_variables: not considering SSP and TRAC data: X\n",
    "#####\n",
    "\n",
    "additional_variables = [\n",
    "    'Population, total',\n",
    "    'Rural population (% of total population)',\n",
    "    'Population ages 15-64 (% of total population)',\n",
    "    'Unemployment, total (% of total labor force) (modeled ILO estimate)',\n",
    "    'Victims of intentional homicide',\n",
    "    'Prevalence of severe food insecurity in the population (%)',\n",
    "    'Prevalence of undernourishment (% of population)',\n",
    "    'Corruption',\n",
    "    'Government Effectiveness: Estimate',\n",
    "    'GDP (current US$)',\n",
    "    'GDP per capita (current US$)'\n",
    "]\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "# Scenario 1: _SSP119_avg_temp = Y\n",
    "##################################################################\n",
    "# Creating a dataframe 'new_features_2023_2100_ssp119' \n",
    "# Years 2023 to 2100\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'new_features_2023_2100_ssp119' = X\n",
    "#####\n",
    "# Filtering data for 'GUA_SSP119_avg_temp'\n",
    "GUA_new_features_2023_2100_ssp119 = predicted_data[predicted_data['Variable'] == 'GUA_SSP119_avg_temp']\n",
    "GUA_new_features_2023_2100_ssp119 = GUA_new_features_2023_2100_ssp119[['Year', 'Value']]  \n",
    "GUA_new_features_2023_2100_ssp119 = GUA_new_features_2023_2100_ssp119.rename(columns={'Value': 'Temperature'})  \n",
    "#####\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "# _SSP119_avg_temp\n",
    "for var in additional_variables:\n",
    "    var_data = predicted_data[predicted_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_new_features_2023_2100_ssp119 = pd.merge(GUA_new_features_2023_2100_ssp119, var_data, on='Year', how='outer')\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# Scenario 2: _SSP245_avg_temp = Y\n",
    "##################################################################\n",
    "# Creating a dataframe 'new_features_2023_2100_ssp245' \n",
    "# Years 2023 to 2100\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'new_features_2023_2100_ssp245' = X\n",
    "#####\n",
    "# Filtering data for 'GUA_SSP245_avg_temp'\n",
    "GUA_new_features_2023_2100_ssp245 = predicted_data[predicted_data['Variable'] == 'GUA_SSP245_avg_temp']\n",
    "GUA_new_features_2023_2100_ssp245 = GUA_new_features_2023_2100_ssp245[['Year', 'Value']]  \n",
    "GUA_new_features_2023_2100_ssp245 = GUA_new_features_2023_2100_ssp245.rename(columns={'Value': 'Temperature'})  \n",
    "#####\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "# _SSP245_avg_temp\n",
    "for var in additional_variables:\n",
    "    var_data = predicted_data[predicted_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_new_features_2023_2100_ssp245 = pd.merge(GUA_new_features_2023_2100_ssp245, var_data, on='Year', how='outer')\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# Scenario 3: _SSP370_avg_temp = Y\n",
    "##################################################################\n",
    "# Creating a dataframe 'new_features_2023_2100_ssp370' \n",
    "# Years 2023 to 2100\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'new_features_2023_2100_ssp370' = X\n",
    "\n",
    "# Filtering data for 'GUA_SSP370_avg_temp'\n",
    "GUA_new_features_2023_2100_ssp370 = predicted_data[predicted_data['Variable'] == 'GUA_SSP370_avg_temp']\n",
    "GUA_new_features_2023_2100_ssp370 = GUA_new_features_2023_2100_ssp370[['Year', 'Value']]  \n",
    "GUA_new_features_2023_2100_ssp370 = GUA_new_features_2023_2100_ssp370.rename(columns={'Value': 'Temperature'})  \n",
    "#####\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "# _SSP370_avg_temp\n",
    "for var in additional_variables:\n",
    "    var_data = predicted_data[predicted_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_new_features_2023_2100_ssp370 = pd.merge(GUA_new_features_2023_2100_ssp370, var_data, on='Year', how='outer')\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# Scenario 4: _SSP585_avg_temp = Y\n",
    "##################################################################\n",
    "# Creating a dataframe 'new_features_2023_2100_ssp585' \n",
    "# Years 2023 to 2100\n",
    "# 'features_ssp119' stores all values from all variables except SSP and TRAC data\n",
    "# 'new_features_2023_2100_ssp585' = X\n",
    "\n",
    "# Filtering data for 'GUA_SSP585_avg_temp'\n",
    "GUA_new_features_2023_2100_ssp585 = predicted_data[predicted_data['Variable'] == 'GUA_SSP585_avg_temp']\n",
    "GUA_new_features_2023_2100_ssp585 = GUA_new_features_2023_2100_ssp585[['Year', 'Value']]  \n",
    "GUA_new_features_2023_2100_ssp585 = GUA_new_features_2023_2100_ssp585.rename(columns={'Value': 'Temperature'})  \n",
    "#####\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "# _SSP585_avg_temp\n",
    "for var in additional_variables:\n",
    "    var_data = predicted_data[predicted_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    GUA_new_features_2023_2100_ssp585 = pd.merge(GUA_new_features_2023_2100_ssp585, var_data, on='Year', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting all NaN values of the additional_variables\n",
    "\n",
    "##################################################################\n",
    "# X2 is getting just the temperature values\n",
    "# new_features_2023_2100_ssp119\n",
    "X2_119_GUA = GUA_new_features_2023_2100_ssp119[['Temperature']]\n",
    "# Here the model is predicting all values and storing them in Y2\n",
    "Y2_119_GUA = model119_GUA.predict(X2_119_GUA)[:,1:]\n",
    "# The additional_variables are now getting the predicted Y2 values\n",
    "GUA_new_features_2023_2100_ssp119[additional_variables] = Y2_119_GUA\n",
    "##################################################################\n",
    "# X2 is getting just the temperature values\n",
    "# new_features_2023_2100_ssp245\n",
    "X2_245_GUA = GUA_new_features_2023_2100_ssp245[['Temperature']]\n",
    "# Here the model is predicting all values and storing them in Y2\n",
    "Y2_245_GUA = model245_GUA.predict(X2_245_GUA)[:,1:]\n",
    "# The additional_variables are now getting the predicted Y2 values\n",
    "GUA_new_features_2023_2100_ssp245[additional_variables] = Y2_245_GUA\n",
    "##################################################################\n",
    "# X2 is getting just the temperature values\n",
    "# new_features_2023_2100_ssp370\n",
    "X2_370_GUA = GUA_new_features_2023_2100_ssp370[['Temperature']]\n",
    "# Here the model is predicting all values and storing them in Y2\n",
    "Y2_370_GUA = model370_GUA.predict(X2_370_GUA)[:,1:]\n",
    "# The additional_variables are now getting the predicted Y2 values\n",
    "GUA_new_features_2023_2100_ssp370[additional_variables] = Y2_370_GUA\n",
    "##################################################################\n",
    "# X2 is getting just the temperature values\n",
    "# new_features_2023_2100_ssp585\n",
    "X2_585_GUA = GUA_new_features_2023_2100_ssp585[['Temperature']]\n",
    "# Here the model is predicting all values and storing them in Y2\n",
    "Y2_585_GUA = model585_GUA.predict(X2_585_GUA)[:,1:]\n",
    "# The additional_variables are now getting the predicted Y2 values\n",
    "GUA_new_features_2023_2100_ssp585[additional_variables] = Y2_585_GUA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting TRAC from all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for temperature projections and historical data\n",
    "\n",
    "# Prediction starts from 2015 because TRAC starts on 2015\n",
    "# long_df goes from 2015 to 2100\n",
    "\n",
    "# Temperature Data from 2023 to 2100, all four SSPs\n",
    "\n",
    "# Historical Data from 2015 to 2022\n",
    "long_hist_data = long_df[long_df['Year'] <= 2022]\n",
    "# Predicted Data from 2023 to 2100\n",
    "long_predicted_data = long_df[long_df['Year'] >= 2023]\n",
    "# Dependent Variables, TRAC Crossings\n",
    "dep_vars = long_hist_data[long_hist_data['Variable'].isin(['GUA_Rio_Grande', 'GUA_San_Diego', 'GUA_San_Diego'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Filter data for 'GUA_SSP119_avg_temp'\n",
    "\n",
    "X1_119_GUA = long_hist_data[long_hist_data['Variable'] == 'GUA_SSP119_avg_temp']\n",
    "X1_119_GUA = X1_119_GUA[['Year', 'Value']]\n",
    "X1_119_GUA = X1_119_GUA.rename(columns={'Value': 'Temperature'})\n",
    "##################################################################\n",
    "# Filter data for 'GUA_SSP245_avg_temp'\n",
    "\n",
    "X1_245_GUA = long_hist_data[long_hist_data['Variable'] == 'GUA_SSP245_avg_temp']\n",
    "X1_245_GUA = X1_245_GUA[['Year', 'Value']]\n",
    "X1_245_GUA = X1_245_GUA.rename(columns={'Value': 'Temperature'})\n",
    "##################################################################\n",
    "# Filter data for 'GUA_SSP370_avg_temp'\n",
    "\n",
    "X1_370_GUA = long_hist_data[long_hist_data['Variable'] == 'GUA_SSP370_avg_temp']\n",
    "X1_370_GUA = X1_370_GUA[['Year', 'Value']]\n",
    "X1_370_GUA = X1_370_GUA.rename(columns={'Value': 'Temperature'})\n",
    "##################################################################\n",
    "# Filter data for 'GUA_SSP585_avg_temp'\n",
    "\n",
    "X1_585_GUA = long_hist_data[long_hist_data['Variable'] == 'GUA_SSP585_avg_temp']\n",
    "X1_585_GUA = X1_585_GUA[['Year', 'Value']]\n",
    "X1_585_GUA = X1_585_GUA.rename(columns={'Value': 'Temperature'})\n",
    "##################################################################\n",
    "\n",
    "# List of additional variables to add to X1\n",
    "\n",
    "additional_variables = [\n",
    "    'Population, total',\n",
    "    'Rural population (% of total population)',\n",
    "    'Population ages 15-64 (% of total population)',\n",
    "    'Unemployment, total (% of total labor force) (modeled ILO estimate)',\n",
    "    'Victims of intentional homicide',\n",
    "    'Prevalence of severe food insecurity in the population (%)',\n",
    "    'Prevalence of undernourishment (% of population)',\n",
    "    'Corruption',\n",
    "    'Government Effectiveness: Estimate',\n",
    "    'GDP (current US$)',\n",
    "    'GDP per capita (current US$)',\n",
    "    'GUA_San_Diego'\n",
    "]\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "for var in additional_variables:\n",
    "    var_data = long_hist_data[long_hist_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    X1_119_GUA = pd.merge(X1_119_GUA, var_data, on='Year', how='outer')\n",
    "# Now X1 contains 'Temperature' along with the additional variables for each year\n",
    "# 2015 to 2022\n",
    "##################################################################\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "for var in additional_variables:\n",
    "    var_data = long_hist_data[long_hist_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    X1_245_GUA = pd.merge(X1_245_GUA, var_data, on='Year', how='outer')\n",
    "# Now X1 contains 'Temperature' along with the additional variables for each year\n",
    "# 2015 to 2022\n",
    "##################################################################\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "for var in additional_variables:\n",
    "    var_data = long_hist_data[long_hist_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    X1_370_GUA = pd.merge(X1_370_GUA, var_data, on='Year', how='outer')\n",
    "# Now X1 contains 'Temperature' along with the additional variables for each year\n",
    "# 2015 to 2022\n",
    "##################################################################\n",
    "# Loop through each additional variable and merge with X1 DataFrame\n",
    "for var in additional_variables:\n",
    "    var_data = long_hist_data[long_hist_data['Variable'] == var][['Year', 'Value']]\n",
    "    var_data = var_data.rename(columns={'Value': var})\n",
    "    X1_585_GUA = pd.merge(X1_585_GUA, var_data, on='Year', how='outer')\n",
    "# Now X1 contains 'Temperature' along with the additional variables for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# _SSP119_avg_temp\n",
    "X1_119_new_GUA = X1_119_GUA[X1_119_GUA['Year'] >= 2015]\n",
    "##################################################################\n",
    "# _SSP245_avg_temp\n",
    "X1_245_new_GUA = X1_245_GUA[X1_245_GUA['Year'] >= 2015]\n",
    "##################################################################\n",
    "# _SSP370_avg_temp\n",
    "X1_370_new_GUA = X1_370_GUA[X1_370_GUA['Year'] >= 2015]\n",
    "##################################################################\n",
    "# _SSP585_avg_temp\n",
    "X1_585_new_GUA = X1_585_GUA[X1_585_GUA['Year'] >= 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1_119_new_GUA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting San_Diego Crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Predicting Y: _SSP119_avg_temp\n",
    "Y1_119_GUA = X1_119_new_GUA[['GUA_San_Diego']]\n",
    "X1_predict_119_GUA = X1_119_new_GUA.drop(columns='GUA_San_Diego')\n",
    "##################################################################\n",
    "# Predicting Y: _SSP245_avg_temp\n",
    "Y1_245_GUA = X1_245_new_GUA[['GUA_San_Diego']]\n",
    "X1_predict_245_GUA = X1_245_new_GUA.drop(columns='GUA_San_Diego')\n",
    "##################################################################\n",
    "# Predicting Y: _SSP370_avg_temp\n",
    "Y1_370_GUA = X1_370_new_GUA[['GUA_San_Diego']]\n",
    "X1_predict_370_GUA = X1_370_new_GUA.drop(columns='GUA_San_Diego')\n",
    "##################################################################\n",
    "# Predicting Y: _SSP585_avg_temp\n",
    "Y1_585_GUA = X1_585_new_GUA[['GUA_San_Diego']]\n",
    "X1_predict_585_GUA = X1_585_new_GUA.drop(columns='GUA_San_Diego')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X1_predict_119_GUA.isnull().sum())\n",
    "print(X1_predict_119_GUA.isin([np.nan, np.inf, -np.inf]).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on TRAC: GUA_San_Diego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training on TRAC: Crossing 1: GUA_San_Diego\n",
    "\n",
    "# _SSP119_avg_temp\n",
    "model1_ssp119_GUA = sm.OLS(Y1_119_GUA, X1_predict_119_GUA).fit()\n",
    "# _SSP245_avg_temp\n",
    "model2_ssp245_GUA = sm.OLS(Y1_245_GUA, X1_predict_245_GUA).fit()\n",
    "# _SSP370_avg_temp\n",
    "model3_ssp370_GUA = sm.OLS(Y1_370_GUA, X1_predict_370_GUA).fit()\n",
    "# _SSP585_avg_temp\n",
    "model4_ssp585_GUA = sm.OLS(Y1_585_GUA, X1_predict_585_GUA).fit()\n",
    "\n",
    "# Saving Model Summaries\n",
    "\n",
    "models_and_data = [\n",
    "    (model1_ssp119_GUA, \"Y1_119_GUA\", \"X1_predict_119_GUA\"),\n",
    "    (model2_ssp245_GUA, \"Y1_245_GUA\", \"X1_predict_245_GUA\"),\n",
    "    (model3_ssp370_GUA, \"Y1_370_GUA\", \"X1_predict_370_GUA\"),\n",
    "    (model4_ssp585_GUA, \"Y1_585_GUA\", \"X1_predict_585_GUA\")\n",
    "]\n",
    "\n",
    "directory_path = \"All_outputs/Guatemala/\"\n",
    "\n",
    "# Iterate over models and save their summaries\n",
    "for model, Y_var, X_var in models_and_data:\n",
    "    fitted_model = sm.OLS(eval(Y_var), eval(X_var)).fit()\n",
    "    model_name = [name for name, obj in globals().items() if obj is model][0]\n",
    "    model_name = f\"Guatemala_San_Diego_{model_name}\"\n",
    "    file_path = f\"{directory_path}{model_name}_summary.txt\"\n",
    "    # Save the model summary as a text file\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(str(fitted_model.summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAC prediction 2023 to 2100: _SSP119_avg_temp\n",
    "predicted_future_imigrants_ssp119_GUA = model1_ssp119_GUA.predict(GUA_new_features_2023_2100_ssp119)\n",
    "# TRAC prediction 2023 to 2100: _SSP245_avg_temp\n",
    "predicted_future_imigrants_ssp245_GUA = model2_ssp245_GUA.predict(GUA_new_features_2023_2100_ssp245)\n",
    "# TRAC prediction 2023 to 2100: _SSP370_avg_temp\n",
    "predicted_future_imigrants_ssp370_GUA = model3_ssp370_GUA.predict(GUA_new_features_2023_2100_ssp370)\n",
    "# TRAC prediction 2023 to 2100: _SSP585_avg_temp\n",
    "predicted_future_imigrants_ssp585_GUA = model4_ssp585_GUA.predict(GUA_new_features_2023_2100_ssp585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Dataframe for SSP119\n",
    "GUA_new_features_2023_2100_ssp119['GUA_San_Diego'] = predicted_future_imigrants_ssp119_GUA\n",
    "# Printing Dataframe for SSP245\n",
    "GUA_new_features_2023_2100_ssp245['GUA_San_Diego'] = predicted_future_imigrants_ssp245_GUA\n",
    "# Printing Dataframe for SSP370\n",
    "GUA_new_features_2023_2100_ssp370['GUA_San_Diego'] = predicted_future_imigrants_ssp370_GUA\n",
    "# Printing Dataframe for SSP585\n",
    "GUA_new_features_2023_2100_ssp585['GUA_San_Diego'] = predicted_future_imigrants_ssp585_GUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Removing duplicated data per year: _SSP119_avg_temp\n",
    "years = GUA_new_features_2023_2100_ssp119['Year'].unique()\n",
    "final_predictions_2023_2100_ssp119_GUA = pd.DataFrame()  \n",
    "for year in years:\n",
    "    first_row = GUA_new_features_2023_2100_ssp119[GUA_new_features_2023_2100_ssp119['Year'] == year].iloc[0]  \n",
    "    final_predictions_2023_2100_ssp119_GUA = pd.concat([final_predictions_2023_2100_ssp119_GUA, pd.DataFrame([first_row])])\n",
    "final_predictions_2023_2100_ssp119_GUA.reset_index(drop=True, inplace=True)\n",
    "final_predictions_2023_2100_ssp119_GUA['Year'] = final_predictions_2023_2100_ssp119_GUA['Year'].astype(int)\n",
    "##################################################################\n",
    "# Removing duplicated data per year: _SSP245_avg_temp\n",
    "years = GUA_new_features_2023_2100_ssp245['Year'].unique()\n",
    "final_predictions_2023_2100_ssp245_GUA = pd.DataFrame()  \n",
    "for year in years:\n",
    "    first_row = GUA_new_features_2023_2100_ssp245[GUA_new_features_2023_2100_ssp245['Year'] == year].iloc[0]  \n",
    "    final_predictions_2023_2100_ssp245_GUA = pd.concat([final_predictions_2023_2100_ssp245_GUA, pd.DataFrame([first_row])])\n",
    "final_predictions_2023_2100_ssp245_GUA.reset_index(drop=True, inplace=True)\n",
    "final_predictions_2023_2100_ssp245_GUA['Year'] = final_predictions_2023_2100_ssp245_GUA['Year'].astype(int)\n",
    "##################################################################\n",
    "# Removing duplicated data per year: _SSP370_avg_temp\n",
    "years = GUA_new_features_2023_2100_ssp370['Year'].unique()\n",
    "final_predictions_2023_2100_ssp370_GUA = pd.DataFrame()  \n",
    "for year in years:\n",
    "    first_row = GUA_new_features_2023_2100_ssp370[GUA_new_features_2023_2100_ssp370['Year'] == year].iloc[0]  \n",
    "    final_predictions_2023_2100_ssp370_GUA = pd.concat([final_predictions_2023_2100_ssp370_GUA, pd.DataFrame([first_row])])\n",
    "final_predictions_2023_2100_ssp370_GUA.reset_index(drop=True, inplace=True)\n",
    "final_predictions_2023_2100_ssp370_GUA['Year'] = final_predictions_2023_2100_ssp370_GUA['Year'].astype(int)\n",
    "##################################################################\n",
    "# Removing duplicated data per year: _SSP585_avg_temp\n",
    "years = GUA_new_features_2023_2100_ssp585['Year'].unique()\n",
    "final_predictions_2023_2100_ssp585_GUA = pd.DataFrame()  \n",
    "for year in years:\n",
    "    first_row = GUA_new_features_2023_2100_ssp585[GUA_new_features_2023_2100_ssp585['Year'] == year].iloc[0]  \n",
    "    final_predictions_2023_2100_ssp585_GUA = pd.concat([final_predictions_2023_2100_ssp585_GUA, pd.DataFrame([first_row])])\n",
    "final_predictions_2023_2100_ssp585_GUA.reset_index(drop=True, inplace=True)\n",
    "final_predictions_2023_2100_ssp585_GUA['Year'] = final_predictions_2023_2100_ssp585_GUA['Year'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting TRAC Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- final_predictions_2023_2100_ssp119\n",
    "final_predictions_2023_2100_ssp245\n",
    "final_predictions_2023_2100_ssp370\n",
    "final_predictions_2023_2100_ssp585 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the index of all DataFrames to 'Year'\n",
    "final_predictions_2023_2100_ssp119_GUA.set_index('Year', inplace=True)\n",
    "final_predictions_2023_2100_ssp245_GUA.set_index('Year', inplace=True)\n",
    "final_predictions_2023_2100_ssp370_GUA.set_index('Year', inplace=True)\n",
    "final_predictions_2023_2100_ssp585_GUA.set_index('Year', inplace=True)\n",
    "###########\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))  # You can adjust the figure size as needed\n",
    "for ssp, label in zip([final_predictions_2023_2100_ssp119_GUA, final_predictions_2023_2100_ssp245_GUA, final_predictions_2023_2100_ssp370_GUA, final_predictions_2023_2100_ssp585_GUA], ['SSP119', 'SSP245', 'SSP370', 'SSP585']):\n",
    "    plt.plot(ssp.index, ssp['GUA_San_Diego'], marker='o', linestyle='-', label=label)\n",
    "###########\n",
    "plt.title('San Diego Crossing: Proyection of Guatemalan Undocumented Immigrants from 2023 to 2100')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('GUA_San_Diego')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"All_outputs/Guatemala/San_Diego_GUA_All_Projections.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data for each scenario\n",
    "def extract_data(final_predictions, scenario):\n",
    "    return pd.DataFrame({\n",
    "        'Scenario': [scenario] * len(final_predictions),\n",
    "        'Year': final_predictions.index,\n",
    "        'Number_of_People': final_predictions['GUA_San_Diego']\n",
    "    })\n",
    "# Extract data for each scenario\n",
    "data_ssp119_GUA = extract_data(final_predictions_2023_2100_ssp119_GUA, 'SSP119')\n",
    "data_ssp245_GUA = extract_data(final_predictions_2023_2100_ssp245_GUA, 'SSP245')\n",
    "data_ssp370_GUA = extract_data(final_predictions_2023_2100_ssp370_GUA, 'SSP370')\n",
    "data_ssp585_GUA = extract_data(final_predictions_2023_2100_ssp585_GUA, 'SSP585')\n",
    "# Concatenating all scenarios into a single DataFrame\n",
    "output_df_GUA = pd.concat([data_ssp119_GUA, data_ssp245_GUA, data_ssp370_GUA, data_ssp585_GUA], ignore_index=True)\n",
    "# Pivot the DataFrame\n",
    "output_df_pivoted_GUA = output_df_GUA.pivot(index='Scenario', columns='Year', values='Number_of_People')\n",
    "# Fill any missing values with 0\n",
    "output_df_pivoted_GUA.fillna(0, inplace=True)\n",
    "\n",
    "# Reformatting dataframe\n",
    "output_df_pivoted_GUA.insert(0, 'Crossing', 'San_Diego_Crossing')\n",
    "output_df_pivoted_GUA.insert(1, 'Country', 'GUA')\n",
    "\n",
    "# Saving dataframe\n",
    "\n",
    "output_df_pivoted_GUA.to_csv(\"All_outputs/Guatemala/San_Diego_GUA_4SSP.csv\", index=True)\n",
    "\n",
    "# Printing\n",
    "output_df_pivoted_GUA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "\n",
    "##################################################################\n",
    "# Using ggplot\n",
    "plt.style.use('ggplot')\n",
    "##################################################################\n",
    "# Color palette\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "##################################################################\n",
    "# Plot size\n",
    "plt.figure(figsize=(15, 5))  # You can adjust the figure size as needed\n",
    "##################################################################\n",
    "# Convert index values to strings\n",
    "output_df_pivoted_GUA.index = output_df_pivoted_GUA.index.astype(str)\n",
    "##################################################################\n",
    "# Selecting every 5th year to display\n",
    "years_to_display = output_df_pivoted_GUA.columns[2:][::5]  # Excluding first two columns\n",
    "##################################################################\n",
    "# Plotting data for each scenario\n",
    "for scenario, color in zip(output_df_pivoted_GUA.index, colors):\n",
    "    plt.plot(output_df_pivoted_GUA.columns[2:].astype(int), output_df_pivoted_GUA.loc[scenario][2:], marker='o', linestyle='-', alpha=0.5, label=scenario, color=color)\n",
    "    for year in years_to_display:\n",
    "        plt.annotate(f'{int(output_df_pivoted_GUA.loc[scenario, year])}', (int(year), output_df_pivoted_GUA.loc[scenario, year]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "plt.title('San Diego Crossing: Undocumented Guatemalan Immigrants')\n",
    "plt.suptitle('Projection from 2023 to 2100: SSP Scenarios')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('People (units)')\n",
    "##################################################################\n",
    "# Linear Regression Equation\n",
    "X = output_df_pivoted_GUA.columns[2:].astype(int).values.reshape(-1, 1)\n",
    "for scenario, color in zip(output_df_pivoted_GUA.index, colors):\n",
    "    y = output_df_pivoted_GUA.loc[scenario][2:].values.reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    m = model.coef_[0][0]\n",
    "    b = model.intercept_[0]\n",
    "    plt.plot(output_df_pivoted_GUA.columns[2:].astype(int), m * output_df_pivoted_GUA.columns[2:].astype(int) + b, label=f'Linear Regression ({scenario}): y = {m:.2f}x + {b:.2f}', color=color)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "##################################################################\n",
    "\n",
    "# Saving graph\n",
    "plt.savefig(\"All_outputs/Guatemala/San_Diego_GUA_4SSP_Single.png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
